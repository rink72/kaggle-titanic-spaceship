{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as sst\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook variables\n",
    "SEED_VALUE = 72\n",
    "TRAIN_SIZE = 0.8\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "DEPTH = 5\n",
    "ESTIMATORS = 25\n",
    "\n",
    "trainDataPath = \"../input/train.csv\"\n",
    "testDataPath = \"../input/test.csv\"\n",
    "\n",
    "outputPath = \"../output/submission-01.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_gradientboosting_model(X_train, X_valid, y_train, y_valid, n_estimators=200, max_depth=20):\n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators, random_state=SEED_VALUE, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds), accuracy_score(y_valid, preds)\n",
    "\n",
    "def score_gradientboosting(X_train, X_valid, y_train, y_valid, params):\n",
    "    scores = []\n",
    "\n",
    "    for e in params[\"n_estimators\"]:\n",
    "      for d in params[\"depth\"]:\n",
    "        mae, accuracy = score_gradientboosting_model(X_train, X_valid, y_train, y_valid, n_estimators=e, max_depth=d)\n",
    "\n",
    "        scores.append(\n",
    "          {\n",
    "            \"type\": \"GradientBoostingClassifier\",\n",
    "            \"mae\": mae,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"estimators\": e,\n",
    "            \"depth\": d\n",
    "          }\n",
    "        )\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def score_randomforest_model(X_train, X_valid, y_train, y_valid, n_estimators=200, max_depth=20):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=SEED_VALUE, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds), accuracy_score(y_valid, preds)\n",
    "\n",
    "def score_randomforest(X_train, X_valid, y_train, y_valid, params):\n",
    "    scores = []\n",
    "\n",
    "    for e in params[\"n_estimators\"]:\n",
    "      for d in params[\"depth\"]:\n",
    "        mae, accuracy = score_randomforest_model(X_train, X_valid, y_train, y_valid, n_estimators=e, max_depth=d)\n",
    "\n",
    "        scores.append(\n",
    "          {\n",
    "            \"type\": \"RandomForestClassifier\",\n",
    "            \"mae\": mae,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"estimators\": e,\n",
    "            \"depth\": d\n",
    "          }\n",
    "        )\n",
    "\n",
    "    return scores\n",
    "\n",
    "def score_adaboost_model(X_train, X_valid, y_train, y_valid):\n",
    "    model = AdaBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds), accuracy_score(y_valid, preds)\n",
    "\n",
    "def score_adaboost(X_train, X_valid, y_train, y_valid, params):\n",
    "    scores = []\n",
    "\n",
    "    mae, accuracy = score_adaboost_model(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    scores.append(\n",
    "      {\n",
    "        \"type\": \"AdaBoostClassifier\",\n",
    "        \"mae\": mae,\n",
    "        \"accuracy\": accuracy\n",
    "      }\n",
    "    )\n",
    "\n",
    "    return scores\n",
    "\n",
    "def score_decisiontree_model(X_train, X_valid, y_train, y_valid, max_depth=20):\n",
    "    model = DecisionTreeClassifier(random_state=SEED_VALUE, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds), accuracy_score(y_valid, preds)\n",
    "\n",
    "def score_decisiontree(X_train, X_valid, y_train, y_valid, params):\n",
    "    scores = []\n",
    "\n",
    "    for d in params[\"depth\"]:\n",
    "      mae, accuracy = score_decisiontree_model(X_train, X_valid, y_train, y_valid, max_depth=d)\n",
    "\n",
    "      scores.append(\n",
    "        {\n",
    "          \"type\": \"DecisionTreeClassifier\",\n",
    "          \"mae\": mae,\n",
    "          \"accuracy\": accuracy,\n",
    "          \"depth\": d\n",
    "        }\n",
    "      )\n",
    "\n",
    "    return scores\n",
    "\n",
    "def score_extratrees_model(X_train, X_valid, y_train, y_valid, n_estimators=200, max_depth=20):\n",
    "    model = ExtraTreesClassifier(n_estimators=n_estimators, random_state=SEED_VALUE, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds), accuracy_score(y_valid, preds)\n",
    "\n",
    "def score_extratrees(X_train, X_valid, y_train, y_valid, params):\n",
    "    scores = []\n",
    "\n",
    "    for e in params[\"n_estimators\"]:\n",
    "      for d in params[\"depth\"]:\n",
    "        mae, accuracy = score_extratrees_model(X_train, X_valid, y_train, y_valid, n_estimators=e, max_depth=d)\n",
    "\n",
    "        scores.append(\n",
    "          {\n",
    "            \"type\": \"ExtraTreesClassifier\",\n",
    "            \"mae\": mae,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"estimators\": e,\n",
    "            \"depth\": d\n",
    "          }\n",
    "        )\n",
    "\n",
    "    return scores\n",
    "\n",
    "def score_lsvc_model(X_train, X_valid, y_train, y_valid):\n",
    "    model = LinearSVC(max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds), accuracy_score(y_valid, preds)\n",
    "\n",
    "def score_lsvc(X_train, X_valid, y_train, y_valid, params):\n",
    "    scores = []\n",
    "\n",
    "    mae, accuracy = score_lsvc_model(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    scores.append(\n",
    "      {\n",
    "        \"type\": \"LinearSVC\",\n",
    "        \"mae\": mae,\n",
    "        \"accuracy\": accuracy\n",
    "      }\n",
    "    )\n",
    "\n",
    "    return scores\n",
    "\n",
    "def create_homeplanet_bins(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData.loc[binData[\"HomePlanet\"].isna(), \"HomePlanet\"] = \"Unknown\"\n",
    "\n",
    "    binData[\"f_HomePlanet\"] = binData[\"HomePlanet\"]\n",
    "\n",
    "    binData = pd.get_dummies(data = binData, columns = [\"f_HomePlanet\"], prefix = [\"f_HomePlanet\"])\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_idgroup_bins(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData[\"f_GroupId\"] = binData.apply(lambda row: row.name.split(\"_\")[0], axis=1)\n",
    "    binData[\"f_GroupCount\"] = binData.groupby([\"f_GroupId\"])[\"f_GroupId\"].transform(\"count\")\n",
    "    \n",
    "    binData[\"f_GroupAlone\"] = 1\n",
    "    binData.loc[binData[\"f_GroupCount\"] > 1, \"f_GroupAlone\"] = 0\n",
    "\n",
    "    binData[\"f_LargeGroup\"] = 0\n",
    "    binData.loc[binData[\"f_GroupCount\"] > 3, \"f_LargeGroup\"] = 1\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_cabin_features(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData[\"Cabin\"] = binData[\"Cabin\"].fillna(\"U/U/U\")\n",
    "    binData[\"f_DeckTemp\"] = binData.apply(lambda row: row[\"Cabin\"].split(\"/\")[0], axis=1)\n",
    "    binData[\"f_CabinNumber\"] = binData.apply(lambda row: row[\"Cabin\"].split(\"/\")[1], axis=1)\n",
    "    binData[\"f_SideTemp\"] = binData.apply(lambda row: row[\"Cabin\"].split(\"/\")[2], axis=1)\n",
    "\n",
    "    binData[\"f_Deck\"] = binData[\"f_DeckTemp\"]\n",
    "    binData = pd.get_dummies(data = binData, columns = [\"f_DeckTemp\"], prefix = [\"f_Deck\"])\n",
    "    \n",
    "    binData[\"f_Side\"] = binData[\"f_SideTemp\"]\n",
    "    binData = pd.get_dummies(data = binData, columns = [\"f_SideTemp\"], prefix = [\"f_Side\"])\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_destination_bins(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData.loc[binData[\"Destination\"].isna(), \"Destination\"] = \"Unknown\"\n",
    "    binData[\"f_HomeDest\"] = binData[\"HomePlanet\"] + \"_\" + binData[\"Destination\"]\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_age_bins(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData.loc[binData[\"Age\"] >= 0, \"f_Age\"] = 0\n",
    "    binData.loc[binData[\"Age\"] > 15, \"f_Age\"] = 1\n",
    "    binData.loc[binData[\"Age\"] > 30, \"f_Age\"] = 2\n",
    "    binData.loc[binData[\"Age\"] > 45, \"f_Age\"] = 3\n",
    "    binData.loc[binData[\"Age\"] > 60, \"f_Age\"] = 4\n",
    "    binData.loc[binData[\"Age\"] > 75, \"f_Age\"] = 5\n",
    "\n",
    "    binData[\"f_Young\"] = 0\n",
    "    binData.loc[binData[\"Age\"] < 15, \"f_Young\"] = 1\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_vip_bins(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData[\"f_vip\"] = 0\n",
    "\n",
    "    binData.loc[binData[\"VIP\"].isna(), \"f_vip\"] = 2\n",
    "    binData.loc[(binData[\"VIP\"] == True), \"f_vip\"] = 1\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_spend_features(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    spendFeatures = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "    outsideSpendFeatures = [\"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "\n",
    "    #binData[\"f_totalspend\"] = binData[spendFeatures].sum(axis=1)\n",
    "    binData[\"f_outsidespend\"] = binData[outsideSpendFeatures].sum(axis=1)\n",
    "\n",
    "    binData.loc[binData[spendFeatures].sum(axis=1) == 0, \"f_totalspend\"] = 0\n",
    "    binData.loc[binData[spendFeatures].sum(axis=1) > 0, \"f_totalspend\"] = 1\n",
    "    binData.loc[binData[spendFeatures].sum(axis=1) > 750, \"f_totalspend\"] = 2\n",
    "    binData[\"f_totalspend\"] = binData[\"f_totalspend\"].fillna(3)\n",
    "\n",
    "    binData.loc[binData[\"RoomService\"] == 0, \"f_RoomService\"] = 0\n",
    "    binData.loc[binData[\"RoomService\"] > 0, \"f_RoomService\"] = 1\n",
    "    binData.loc[binData[\"RoomService\"] > 100, \"f_RoomService\"] = 2\n",
    "    binData[\"f_RoomService\"] = binData[\"f_RoomService\"].fillna(3)\n",
    "\n",
    "    binData.loc[binData[\"FoodCourt\"] == 0, \"f_FoodCourt\"] = 0\n",
    "    binData.loc[binData[\"FoodCourt\"] > 0, \"f_FoodCourt\"] = 1\n",
    "    binData.loc[binData[\"FoodCourt\"] > 100, \"f_FoodCourt\"] = 2\n",
    "    binData[\"f_FoodCourt\"] = binData[\"f_FoodCourt\"].fillna(3)\n",
    "\n",
    "    binData.loc[binData[\"ShoppingMall\"] == 0, \"f_ShoppingMall\"] = 0\n",
    "    binData.loc[binData[\"ShoppingMall\"] > 0, \"f_ShoppingMall\"] = 1\n",
    "    binData.loc[binData[\"ShoppingMall\"] > 100, \"f_ShoppingMall\"] = 2\n",
    "    binData[\"f_ShoppingMall\"] = binData[\"f_ShoppingMall\"].fillna(3)\n",
    "\n",
    "    binData.loc[binData[\"Spa\"] == 0, \"f_Spa\"] = 0\n",
    "    binData.loc[binData[\"Spa\"] > 0, \"f_Spa\"] = 1\n",
    "    binData.loc[binData[\"Spa\"] > 100, \"f_Spa\"] = 2\n",
    "    binData[\"f_Spa\"] = binData[\"f_Spa\"].fillna(3)\n",
    "\n",
    "    binData.loc[binData[\"VRDeck\"] == 0, \"f_VRDeck\"] = 0\n",
    "    binData.loc[binData[\"VRDeck\"] > 0, \"f_VRDeck\"] = 1\n",
    "    binData.loc[binData[\"VRDeck\"] > 100, \"f_VRDeck\"] = 2\n",
    "    binData[\"f_VRDeck\"] = binData[\"f_VRDeck\"].fillna(3)\n",
    "\n",
    "    binData[\"f_ZeroSpend\"] = 0\n",
    "    binData.loc[binData[\"f_totalspend\"] == 0, \"f_ZeroSpend\"] = 1\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_cryo_bins(data):\n",
    "    binData = data.copy()\n",
    "\n",
    "    binData[\"f_Cryo\"] = 0\n",
    "\n",
    "    binData.loc[binData[\"CryoSleep\"].isna(), \"f_Cryo\"] = 2\n",
    "    binData.loc[(binData[\"CryoSleep\"] == True), \"f_Cryo\"] = 1\n",
    "\n",
    "    # We assume that anyone that was unknown and didn't spend any money was in cryo\n",
    "    # We assume that anyone that was unknown and did spend money was not in cryo\n",
    "    binData.loc[(binData[\"f_Cryo\"] == 2) & (binData[\"f_totalspend\"] == 0), \"f_Cryo\"] = 1\n",
    "    binData.loc[(binData[\"f_Cryo\"] == 2) & (binData[\"f_totalspend\"] > 0), \"f_Cryo\"] = 0\n",
    "\n",
    "    return binData\n",
    "\n",
    "def create_features(data):\n",
    "  featureData = data.copy()\n",
    "\n",
    "  featureData = create_homeplanet_bins(featureData)\n",
    "  featureData = create_idgroup_bins(featureData)\n",
    "  featureData = create_cabin_features(featureData)\n",
    "  featureData = create_destination_bins(featureData)\n",
    "  featureData = create_age_bins(featureData)\n",
    "  featureData = create_vip_bins(featureData)\n",
    "  featureData = create_spend_features(featureData)\n",
    "  featureData = create_cryo_bins(featureData)\n",
    "\n",
    "  return featureData\n",
    "\n",
    "def score_models(X_train, X_valid, y_train, y_valid):\n",
    "  randomForestParams = {\n",
    "    \"n_estimators\": [5, 10, 25, 50, 100],\n",
    "    \"depth\": [1, 5, 10, 20]\n",
    "  }\n",
    "\n",
    "  gradientBoostingParams = {\n",
    "    \"n_estimators\": [5, 10, 25, 50, 100],\n",
    "    \"depth\": [1, 5, 10, 20]\n",
    "  }\n",
    "\n",
    "  decisionTreeParams = {\n",
    "    \"depth\": [1, 5, 10, 20, 50, 100]\n",
    "  }\n",
    "\n",
    "  extraTreesParams = {\n",
    "    \"n_estimators\": [5, 10, 25, 50, 100, 200, 500, 100],\n",
    "    \"depth\": [1, 5, 10, 20, 50, 100]\n",
    "  }\n",
    "\n",
    "  linearSVCParams = {}\n",
    "\n",
    "  scores = []\n",
    "  scores = scores + (score_gradientboosting(X_train, X_valid, y_train, y_valid, gradientBoostingParams))\n",
    "  scores = scores + (score_randomforest(X_train, X_valid, y_train, y_valid, randomForestParams))\n",
    "  scores = scores + (score_decisiontree(X_train, X_valid, y_train, y_valid, decisionTreeParams))\n",
    "  scores = scores + (score_extratrees(X_train, X_valid, y_train, y_valid, extraTreesParams))\n",
    "  scores = scores + (score_lsvc(X_train, X_valid, y_train, y_valid, linearSVCParams))\n",
    "  scores = scores + (score_adaboost(X_train, X_valid, y_train, y_valid, {}))\n",
    "\n",
    "  return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load initial data\n",
    "\n",
    "trainData = pd.read_csv(trainDataPath, index_col=\"PassengerId\")\n",
    "trainTarget = trainData.pop(\"Transported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process training data\n",
    "\n",
    "We will remove:\n",
    "\n",
    "- passengerId - not required\n",
    "- age (we will initially drop this and look at adding it back in later with some missing data estimates)\n",
    "- ticket\n",
    "- cabin\n",
    "\n",
    "We will convert:\n",
    "\n",
    "- sex - ordinal encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>...</th>\n",
       "      <th>f_vip</th>\n",
       "      <th>f_outsidespend</th>\n",
       "      <th>f_totalspend</th>\n",
       "      <th>f_RoomService</th>\n",
       "      <th>f_FoodCourt</th>\n",
       "      <th>f_ShoppingMall</th>\n",
       "      <th>f_Spa</th>\n",
       "      <th>f_VRDeck</th>\n",
       "      <th>f_ZeroSpend</th>\n",
       "      <th>f_Cryo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10340.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_02</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "PassengerId                                                         \n",
       "0001_01         Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "0002_01          Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "0003_01         Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "0003_02         Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "0004_01          Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "             RoomService  FoodCourt  ShoppingMall     Spa  ...  f_vip  \\\n",
       "PassengerId                                                ...          \n",
       "0001_01              0.0        0.0           0.0     0.0  ...      0   \n",
       "0002_01            109.0        9.0          25.0   549.0  ...      0   \n",
       "0003_01             43.0     3576.0           0.0  6715.0  ...      1   \n",
       "0003_02              0.0     1283.0         371.0  3329.0  ...      0   \n",
       "0004_01            303.0       70.0         151.0   565.0  ...      0   \n",
       "\n",
       "            f_outsidespend  f_totalspend  f_RoomService  f_FoodCourt  \\\n",
       "PassengerId                                                            \n",
       "0001_01                0.0           0.0            0.0          0.0   \n",
       "0002_01              627.0           1.0            2.0          1.0   \n",
       "0003_01            10340.0           2.0            1.0          2.0   \n",
       "0003_02             5176.0           2.0            0.0          2.0   \n",
       "0004_01              788.0           2.0            2.0          1.0   \n",
       "\n",
       "             f_ShoppingMall f_Spa  f_VRDeck  f_ZeroSpend  f_Cryo  \n",
       "PassengerId                                                       \n",
       "0001_01                 0.0   0.0       0.0            1       0  \n",
       "0002_01                 1.0   2.0       1.0            0       0  \n",
       "0003_01                 0.0   2.0       1.0            0       0  \n",
       "0003_02                 2.0   2.0       2.0            0       0  \n",
       "0004_01                 2.0   2.0       1.0            0       0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "ppData = create_features(trainData)\n",
    "\n",
    "ppData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model\n",
    "\n",
    "Our first attempt at creating a model will use `Sex`, `Fare` and `Pclass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, n_estimators=25, random_state=72)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "features = [\"f_Cryo\", \"f_Deck_B\", \"f_Deck_E\", \"f_Deck_C\", \"f_Side_S\", \"f_ZeroSpend\", \"f_Young\", \"f_totalspend\"]\n",
    "model = GradientBoostingClassifier(n_estimators=ESTIMATORS, random_state=SEED_VALUE, max_depth=DEPTH)\n",
    "model.fit(ppData[features], trainTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index Transported invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\git\\kaggle-titanic-spaceship\\src\\submission-01.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/kaggle-titanic-spaceship/src/submission-01.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39m# Make predictions and save csv\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/git/kaggle-titanic-spaceship/src/submission-01.ipynb#ch0000009?line=2'>3</a>\u001b[0m testData \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(testDataPath, index_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTransported\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/kaggle-titanic-spaceship/src/submission-01.ipynb#ch0000009?line=3'>4</a>\u001b[0m predictionData \u001b[39m=\u001b[39m create_features(testData)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/kaggle-titanic-spaceship/src/submission-01.ipynb#ch0000009?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(predictionData[features])\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=579'>580</a>\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=580'>581</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1250\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=1247'>1248</a>\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=1248'>1249</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=1249'>1250</a>\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=1250'>1251</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/readers.py?line=1251'>1252</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:311\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=307'>308</a>\u001b[0m     data \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, (i, v) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(names, data_tups)}\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=309'>310</a>\u001b[0m     names, date_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_date_conversions(names, data)\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=310'>311</a>\u001b[0m     index, names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_index(date_data, alldata, names)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=312'>313</a>\u001b[0m \u001b[39m# maybe create a mi on the columns\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=313'>314</a>\u001b[0m conv_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_make_multi_index_columns(names, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_names)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:389\u001b[0m, in \u001b[0;36mParserBase._make_index\u001b[1;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=385'>386</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=387'>388</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_complex_date_col:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=388'>389</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_simple_index(alldata, columns)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=389'>390</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_index(index)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=390'>391</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_complex_date_col:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:421\u001b[0m, in \u001b[0;36mParserBase._get_simple_index\u001b[1;34m(self, data, columns)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=418'>419</a>\u001b[0m index \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=419'>420</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=420'>421</a>\u001b[0m     i \u001b[39m=\u001b[39m ix(idx)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=421'>422</a>\u001b[0m     to_remove\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=422'>423</a>\u001b[0m     index\u001b[39m.\u001b[39mappend(data[i])\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:416\u001b[0m, in \u001b[0;36mParserBase._get_simple_index.<locals>.ix\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=413'>414</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=414'>415</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m col\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/pandas/io/parsers/base_parser.py?line=415'>416</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIndex \u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m invalid\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Index Transported invalid"
     ]
    }
   ],
   "source": [
    "# Make predictions and save csv\n",
    "\n",
    "testData = pd.read_csv(testDataPath, index_col=\"PassengerId\")\n",
    "predictionData = create_features(testData)\n",
    "\n",
    "predictions = model.predict(predictionData[features])\n",
    "\n",
    "testData[\"Transported\"] = predictions\n",
    "testData[\"Transported\"].to_csv(outputPath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
